# Machine Learning 상식 정리
- 텐서 플로우 블로그(핸즈온 머신러닝)를 보고 기억하고 있어야 할 것들 간단 정리

## 머신러닝의 간단 정의
- 지속적인 프로그래밍 없이 스스로 학습하여 특정한 결과를 도출하는 연구 분야

## 머신러닝의 효과가 뛰어난 분야
- 기존 솔루션으로는 지속적인 수정과 유지보수가 필요한 문제
- 전통적인 해결방식으로는 너무 복잡하여 해결할 수 없는 문제 
- 유동적인 환경에서의 문제 해결 : 데이터 추가시 지속적인 학습이 가능 
- 복잡한 문제와 대량의 데이터에서 새로운 통찰 얻기

## 머신러닝 시스템의 종류
- 머신러닝 시스템의 종류는 굉장히 많지만, 다음과 같이 크게 분류할 수 있음

### 학습하는 동안의 감독 형태와 정보량에 따른 분류
- 지도 학습
- 비지도 학습
  - ex) 블로그 방문자에 대한 계층적 군집 분석
- 준지도 학습(semi-supervised Learning)
  - 대부분의 데이터가 레이블이 없고 몇 개만 레이블이 있는 경우 학습할 경우 준지도 학습이라고 함
  - ex) 구글 포토 호스팅 서비스
- 강화 학습(reinforcement Learning)
  - 학습하는 시스템을 에이전트라고 부르며 환경을 관찰하여 행동을 실행하고 그 결과 보상 또는 벌점을 받는 형태
  - 시간이 지나면 최고의 보상을 받기위한 정책(policy)라고 부르는 최상의 전략을 스스로 학습함

### 배치 학습과 온라인 학습
- 온라인 학습
  - 모델 학습에 필요한 데이터를 부분적으로 사용하여 모델을 만들어내는 학습 방법
  - 데이터를 순차적으로 미니배치라고 부르는 작은 묶음 단위 또는 한개씩 학습시킴
  - 온라인 학습이라는 용어에 혼동x, 보통 오프라인에서 학습함
- 배치 학습  
  - 모델 학습에 필요한 데이터를 한꺼번에 사용해 모델을 만들어내는 학습 방법
  - 모델이 데이터를 기반으로 점진적으로 학습할 수 없음
  - 많은 컴퓨팅 자원이 필요
  
### 사례 기반 학습과 모델 기반 학습 
- 머신러닝 시스템은 어떻게 모델이 일반화 되는가에 따라 달라질 수 있음
- 사례 기반 학습
  - 데이터의 사례를 기억하여 학습하는 형태
  - 유사도 측정을 통해 새로 들어온 데이터를 일반화함
- 모델 기반 학습
  - 데이터를 학습하여 가장 잘 일반화할 수 있는 가중치(파라미터) 값을 정하는 모델 기반 학습
  - 이 모델을 만들어 예측에 사용

## 나쁜 데이터란? 
- 충분하지 않는 양의 데이터
- 대표성이 없는 데이터  
  - 샘플링 잡음, 샘플링 편향 등을 조심해야 함
- 낮은 품질의 데이터  
  - 많은 data noise, data 결측, 이상치 등..
- 관련 없는 특성
  - feature selection, feature extraction 등을 수행

## 나쁜 모델
- 훈련 데이터 과대적합(overfitting)
  - overfitting을 줄이려면, 데이터 증가시키기  
  - 모델 규제(regularization)
  - 데이터 잡음 줄이기
  - 모델 제약을 가하여 단순화 시키기  
- 훈련 데이터 과소적합(underfitting)
  - 특성 추가
  - 파라미터가 더 많은 모델로 변경
  - 규제 줄이기

## 테스트와 검증
- 테스트 데이터로 오류율을 계산하는 것을 <b>일반화 오차(generalization error), 또는 외부 샘플 오차(out-of-sample error)라고 함</b>
- <b>하이퍼파라미터 튜닝 검증 위하여 테스트 데이터를 여러번 사용하게 되면 테스트 데이터에 과적합될 우려가 있으므로, 하이퍼파라미터 튜닝시 validation set 사용해야 함</b>
- 가장 좋은 방법은 테스트 세트로 단 한번의 테스트를 수행하는 것
- <b>데이비드 윌퍼트는 데이터에 관해 완벽하게 어떠한 가정도 하지 않으면 특정 모델을 선택할 어떠한 근거도 없다고 말함</b> --> NFL(No Free Launch) 이론이라고 함

## 큰그림 보기
- 제곱항을 합한 것의 제곱근(RMSE)의 계산은 <b>유클리디안 노름</b>이라고 함
- 절댓값의 합을 구하는 노름은 <b>맨해튼 노름</b>이라고 함
- 노름의 지수가 클수록 이상치 값에 민감함